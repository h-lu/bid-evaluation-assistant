# 辅助评标专家系统 —— 全流程技术栈选型指南（2026最佳实践）

> 调研时间：2026年2月20日
> 版本：v1.0

---

## 一、技术栈全景图

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           辅助评标专家系统技术栈                                   │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐        │
│  │ 文档解析层   │   │ 检索增强层   │   │ 智能体层    │   │ 应用服务层   │        │
│  ├─────────────┤   ├─────────────┤   ├─────────────┤   ├─────────────┤        │
│  │ MinerU 2.5  │   │ BGE-M3      │   │ LangGraph   │   │ FastAPI     │        │
│  │ PaddleOCR   │   │ ChromaDB    │   │ CrewAI      │   │ Pydantic v2 │        │
│  │ Unstructured│   │ BGE-Reranker│   │ ReAct       │   │ Uvicorn     │        │
│  └─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘        │
│                                                                                 │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐        │
│  │ 大模型层    │   │ 评估监控层   │   │ 部署推理层   │   │ 可观测性层   │        │
│  ├─────────────┤   ├─────────────┤   ├─────────────┤   ├─────────────┤        │
│  │ DeepSeek    │   │ DeepEval    │   │ vLLM        │   │ LangSmith   │        │
│  │ Qwen        │   │ RAGAS       │   │ TensorRT-LLM│   │ Langfuse    │        │
│  │ GPT-4o      │   │ CostTracker │   │ Docker/K8s  │   │ Prometheus  │        │
│  └─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘        │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 二、各层技术选型详解

### 2.1 文档解析层

#### PDF/图片解析工具对比

| 工具 | 准确率 | 速度 | 最佳场景 | 2026推荐度 |
|------|--------|------|----------|-----------|
| **MinerU 2.5** | 92-95% | 中 | 中文文档、RAG系统 | ⭐⭐⭐⭐⭐ |
| **PaddleOCR-VL** | 92.56% | 最快 | 多语言、工业部署 | ⭐⭐⭐⭐⭐ |
| **DeepSeek-OCR** | 97% | 慢 | 学术论文、公式 | ⭐⭐⭐⭐ |
| **Unstructured.io** | 85-90% | 快 | 通用文档处理 | ⭐⭐⭐⭐ |

**评标系统推荐方案**：
```python
# 混合解析策略
class BidDocumentParser:
    def parse(self, file_path: str) -> dict:
        # 1. PDF文档 → MinerU（中文优化）
        if file_path.endswith('.pdf'):
            return MinerUParser().parse(file_path)

        # 2. 图片/扫描件 → PaddleOCR
        elif file_path.endswith(('.jpg', '.png')):
            return PaddleOCRParser().parse(file_path)

        # 3. 复杂表格 → PaddleOCR PP-StructureV3
        elif self._has_complex_tables(file_path):
            return PaddleOCRStructureParser().parse(file_path)
```

**关键配置**：
```yaml
# MinerU配置
mineru:
  model: magic-pdf
  output_format: markdown  # 多模态Markdown
  enable_ocr: auto         # 自动检测乱码切换OCR
  device: cuda             # CUDA/NPU/MPS

# PaddleOCR配置
paddleocr:
  model: PP-OCRv4
  structure: PP-StructureV3  # 表格识别
  lang: ch                   # 中文
```

---

### 2.2 检索增强层（RAG）

#### 2.2.1 Embedding模型选型

| 模型 | 维度 | 最大长度 | C-MTEB分数 | 部署方式 | 推荐度 |
|------|------|----------|-----------|----------|--------|
| **BGE-M3** | 1024 | 8192 | 66.31 | 本地/云端 | ⭐⭐⭐⭐⭐ |
| **BGE-large-zh-v1.5** | 1024 | 512 | 64.53 | 本地/云端 | ⭐⭐⭐⭐⭐ |
| **text-embedding-3-large** | 3072 | 8191 | - | API | ⭐⭐⭐⭐ |
| **m3e-base** | 768 | 512 | - | 本地 | ⭐⭐⭐ |

**评标系统推荐**：
```python
# 推荐使用BGE-M3（长文本+高精度）
from FlagEmbedding import BGEM3FlagModel

model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)

# 支持三种检索模式
embeddings = model.encode(
    documents,
    return_dense=True,      # 稠密向量
    return_sparse=True,     # 稀疏向量（类似BM25）
    return_colbert_vecs=True  # ColBERT向量
)
```

#### 2.2.2 向量数据库选型

| 数据库 | 特点 | 适用场景 | 推荐度 |
|--------|------|----------|--------|
| **ChromaDB** | 轻量、易用、开源 | 中小规模、快速原型 | ⭐⭐⭐⭐⭐ |
| **Milvus** | 十亿级、混合检索 | 大规模生产环境 | ⭐⭐⭐⭐⭐ |
| **Qdrant** | 高性能、过滤能力强 | 需要复杂过滤 | ⭐⭐⭐⭐ |
| **Weaviate** | GraphQL、多模态 | 多模态检索 | ⭐⭐⭐⭐ |

**评标系统推荐**：
```python
# 开发/测试环境：ChromaDB
from chromadb import Client
chroma_client = Client()

# 生产环境：Milvus（支持混合检索）
from pymilvus import connections, Collection
connections.connect(host='localhost', port='19530')
```

#### 2.2.3 Reranker选型

| 模型 | 语言 | 显存 | 准确率 | 推荐度 |
|------|------|------|--------|--------|
| **BGE-Reranker-v2-m3** | 多语言 | ~2GB | 高 | ⭐⭐⭐⭐⭐ |
| **bge-reranker-large** | 中英文 | ~2GB | 高 | ⭐⭐⭐⭐⭐ |
| **Cohere rerank-v3** | 100+语言 | API | 最高 | ⭐⭐⭐⭐ |
| **FlashRank** | 通用 | CPU | 中 | ⭐⭐⭐ |

**评标系统推荐**：
```python
from sentence_transformers import CrossEncoder

# 中文场景首选
reranker = CrossEncoder('BAAI/bge-reranker-large', max_length=512)

# 重排序流程
def rerank_results(query: str, documents: list, top_k: int = 5):
    pairs = [[query, doc] for doc in documents]
    scores = reranker.predict(pairs)
    ranked = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
    return ranked[:top_k]
```

#### 2.2.4 RAG最佳实践（2026）

根据复旦大学研究论文《Searching for Best Practices in Retrieval-Augmented Generation》：

| 组件 | 最佳实践 |
|------|----------|
| **查询分类** | 使用BERT判断是否需要检索 |
| **分块策略** | Small-to-Big（175 tokens小 + 512 tokens大） |
| **检索方法** | 混合检索 + HyDE（α=0.3稀疏/稠密平衡） |
| **重排序** | DLM或TILDE方法 |
| **文档排列** | "Two-sides"（最相关文档放两端） |
| **压缩** | LongLLMLingua查询感知压缩 |

---

### 2.3 大模型层

#### 中文大模型选型

| 模型 | 开发者 | 特点 | 适用场景 | 推荐度 |
|------|--------|------|----------|--------|
| **DeepSeek-V3** | 幻方量化 | MoE+MLA、推理快 | 代码、数学、企业级 | ⭐⭐⭐⭐⭐ |
| **Qwen 3** | 阿里 | 全系列开源、中文优美 | 内容生成、通用任务 | ⭐⭐⭐⭐⭐ |
| **GLM-4.6** | 智谱AI | 知识图谱增强 | 法律、金融、专业领域 | ⭐⭐⭐⭐ |
| **Yi-1.5** | 零一万物 | 平衡效率 | 轻量部署 | ⭐⭐⭐ |

**评标系统模型选择策略**：
```python
# 按Agent职责选择模型
MODEL_CONFIG = {
    # 复杂推理 - 使用大模型
    "coordinator": {
        "model": "deepseek-chat",      # MoE架构，推理效率高
        "reason": "需要理解复杂任务"
    },
    "technical_reviewer": {
        "model": "qwen-max",           # 中文理解能力强
        "reason": "技术方案深度分析"
    },
    "anomaly_detector": {
        "model": "deepseek-chat",
        "reason": "模式识别、推理"
    },

    # 简单规则任务 - 使用小模型
    "qualification_checker": {
        "model": "qwen-turbo",         # 快速、成本低
        "reason": "规则明确的资质核查"
    },
    "price_calculator": {
        "model": "qwen-turbo",
        "reason": "数学计算"
    },
    "report_generator": {
        "model": "qwen-plus",
        "reason": "模板化报告生成"
    }
}
```

**成本对比**（单次评标预估）：

| Agent | 模型 | 调用次数 | 单次成本 | 小计 |
|-------|------|----------|----------|------|
| 协调者 | DeepSeek | 2-3 | $0.005 | $0.015 |
| 技术评审 | Qwen-Max | 5-10 | $0.01 | $0.10 |
| 资格审查 | Qwen-Turbo | 3-5 | $0.001 | $0.005 |
| 价格计算 | Qwen-Turbo | 1-2 | $0.001 | $0.002 |
| 审核者 | DeepSeek | 1-2 | $0.01 | $0.02 |
| **总计** | - | - | - | **~$0.14** |

---

### 2.4 智能体层

#### 多Agent框架对比

| 框架 | 核心抽象 | 学习曲线 | 内置工具 | 最佳场景 | 推荐度 |
|------|----------|----------|----------|----------|--------|
| **LangGraph** | 状态机图 | 中等 | 依赖LangChain | 精细控制、合规审计 | ⭐⭐⭐⭐⭐ |
| **CrewAI** | 角色-任务-团队 | 极低 | 50+预置 | 快速原型、企业应用 | ⭐⭐⭐⭐⭐ |
| **AutoGen** | 多Agent对话 | 陡峭 | 有限 | 研究实验、迭代优化 | ⭐⭐⭐ |

**选型决策树**：
```
需要精细控制每一步？ → LangGraph
工作流映射到团队角色？ → CrewAI
需要迭代对话优化？ → AutoGen
快速原型开发？ → CrewAI
合规审计需求？ → LangGraph

推荐：评标系统用 LangGraph（可追溯性）+ CrewAI（快速开发）组合
```

**评标系统Agent架构**：
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class BidEvaluationState(TypedDict):
    bid_document: dict
    tender_requirements: dict
    qualification_result: dict
    technical_score: dict
    price_score: dict
    anomaly_alerts: list
    final_report: dict

# LangGraph工作流
workflow = StateGraph(BidEvaluationState)

# 添加节点
workflow.add_node("qualification_check", qualification_agent)
workflow.add_node("technical_review", technical_agent)
workflow.add_node("price_evaluation", price_agent)
workflow.add_node("anomaly_detection", anomaly_agent)
workflow.add_node("human_review", human_review_node)
workflow.add_node("report_generation", report_agent)

# 定义边（执行流程）
workflow.set_entry_point("qualification_check")
workflow.add_edge("qualification_check", "technical_review")
workflow.add_edge("technical_review", "price_evaluation")
workflow.add_edge("price_evaluation", "anomaly_detection")
workflow.add_conditional_edges(
    "anomaly_detection",
    should_human_review,  # 条件判断
    {
        "human": "human_review",
        "auto": "report_generation"
    }
)
workflow.add_edge("human_review", "report_generation")
workflow.add_edge("report_generation", END)
```

---

### 2.5 评估监控层

#### LLM评估框架对比

| 框架 | 核心指标 | 最佳场景 | 推荐度 |
|------|----------|----------|--------|
| **RAGAS** | 8个RAG核心指标 | RAG系统研发 | ⭐⭐⭐⭐⭐ |
| **DeepEval** | 40+指标、CI/CD | 企业级生产部署 | ⭐⭐⭐⭐⭐ |
| **TruLens** | 可视化+反馈循环 | 可解释性需求 | ⭐⭐⭐⭐ |

**评标系统评估指标**：
```python
# RAGAS核心指标
RAGAS_METRICS = {
    "context_precision": "检索到的法规/标准是否相关",
    "context_recall": "是否找到了所有需要的法规",
    "faithfulness": "评分建议是否忠实于招标文件",
    "answer_relevancy": "回答是否针对评标问题"
}

# 评标特有指标
BID_EVALUATION_METRICS = {
    "qualification_accuracy": "资质核查准确率",
    "scoring_consistency": "AI评分与专家一致性",
    "regulation_compliance": "法规引用正确率",
    "anomaly_detection_precision": "异常检测精确率"
}

# 使用DeepEval进行CI/CD集成
from deepeval import evaluate
from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric

def run_evaluation(test_cases):
    metrics = [
        HallucinationMetric(threshold=0.85),
        AnswerRelevancyMetric(threshold=0.9)
    ]
    return evaluate(test_cases, metrics)
```

---

### 2.6 部署推理层

#### 推理框架对比（2026）

| 框架 | 吞吐量(tokens/s) | 特点 | 推荐度 |
|------|-----------------|------|--------|
| **vLLM** | ~220 | PagedAttention、开源标准 | ⭐⭐⭐⭐⭐ |
| **TensorRT-LLM** | ~310 | NVIDIA专属、极致性能 | ⭐⭐⭐⭐ |
| **SGLang** | - | 多轮对话优化 | ⭐⭐⭐⭐ |
| **llama.cpp** | - | 跨平台、CPU优先 | ⭐⭐⭐ |

> **重要变化**：TGI (Hugging Face) 自2025年12月起进入维护模式，新项目不推荐使用。

**部署方案**：
```yaml
# docker-compose.yml
version: '3.8'
services:
  # vLLM推理服务
  vllm:
    image: vllm/vllm-openai:latest
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=Qwen/Qwen2.5-72B-Instruct
      - TENSOR_PARALLEL_SIZE=2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]

  # API服务
  api:
    build: .
    ports:
      - "8080:8080"
    environment:
      - LLM_ENDPOINT=http://vllm:8000
    depends_on:
      - vllm
      - chromadb

  # 向量数据库
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma

volumes:
  chroma_data:
```

---

### 2.7 可观测性层

#### 监控工具对比

| 工具 | 特点 | 部署方式 | 推荐度 |
|------|------|----------|--------|
| **LangSmith** | LangChain官方、功能最强 | SaaS | ⭐⭐⭐⭐⭐ |
| **Langfuse** | 开源、私有化首选 | 自托管 | ⭐⭐⭐⭐⭐ |
| **Arize Phoenix** | 开源、RAG可视化 | 自托管 | ⭐⭐⭐⭐ |
| **W&B Weave** | ML实验管理 | SaaS | ⭐⭐⭐⭐ |

**推荐配置**：
```python
# 私有化部署 - Langfuse
from langfuse import Langfuse

langfuse = Langfuse(
    public_key="xxx",
    secret_key="xxx",
    host="http://localhost:3000"  # 自托管地址
)

# 追踪LLM调用
@langfuse.observe()
async def evaluate_bid(bid_document):
    # 自动记录输入、输出、延迟、成本
    result = await agent.run(bid_document)
    return result
```

**监控指标**：
```python
# 关键监控指标
METRICS = {
    # 性能指标
    "latency_p50": "50%请求延迟",
    "latency_p95": "95%请求延迟",
    "latency_p99": "99%请求延迟",
    "throughput": "吞吐量（请求/秒）",

    # 成本指标
    "tokens_per_request": "每次请求Token数",
    "cost_per_request": "每次请求成本",
    "cost_by_agent": "按Agent分组的成本",

    # 质量指标
    "error_rate": "错误率",
    "hallucination_rate": "幻觉率",
    "user_satisfaction": "用户满意度"
}
```

---

### 2.8 应用服务层

#### FastAPI最佳实践

```python
from fastapi import FastAPI, Depends, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List
import asyncio
from functools import lru_cache

# ===== 1. 结构化输入输出 =====
class BidEvaluationRequest(BaseModel):
    """评标请求"""
    bid_document_path: str = Field(..., description="投标文件路径")
    tender_id: str = Field(..., description="招标项目ID")
    enable_human_review: bool = Field(default=True, description="启用人工审核")

class BidEvaluationResponse(BaseModel):
    """评标响应"""
    qualification_result: dict
    technical_score: float = Field(..., ge=0, le=100)
    price_score: float = Field(..., ge=0, le=100)
    total_score: float = Field(..., ge=0, le=100)
    anomaly_alerts: List[dict]
    recommendations: str

# ===== 2. 异步处理 =====
app = FastAPI(title="辅助评标专家系统API")

@app.post("/api/v1/evaluate", response_model=BidEvaluationResponse)
async def evaluate_bid(
    request: BidEvaluationRequest,
    current_user = Depends(get_current_user)
):
    """评标接口 - 异步处理"""
    # 并行执行多个Agent
    qualification_task = asyncio.create_task(
        qualification_agent.check(request.bid_document_path)
    )
    technical_task = asyncio.create_task(
        technical_agent.review(request.bid_document_path)
    )
    price_task = asyncio.create_task(
        price_agent.calculate(request.bid_document_path)
    )

    # 等待所有任务完成
    results = await asyncio.gather(
        qualification_task,
        technical_task,
        price_task
    )

    return BidEvaluationResponse(
        qualification_result=results[0],
        technical_score=results[1]['score'],
        price_score=results[2]['score'],
        total_score=results[1]['score'] + results[2]['score'],
        anomaly_alerts=[],
        recommendations="..."
    )

# ===== 3. 流式响应（SSE）=====
from fastapi.responses import StreamingResponse
import json

@app.post("/api/v1/evaluate/stream")
async def evaluate_bid_stream(request: BidEvaluationRequest):
    """评标接口 - 流式响应"""

    async def event_generator():
        # 阶段1：资格审查
        yield f"data: {json.dumps({'stage': 'qualification', 'status': 'processing'})}\n\n"
        qual_result = await qualification_agent.check(request.bid_document_path)
        yield f"data: {json.dumps({'stage': 'qualification', 'result': qual_result})}\n\n"

        # 阶段2：技术评审
        yield f"data: {json.dumps({'stage': 'technical', 'status': 'processing'})}\n\n"
        tech_result = await technical_agent.review(request.bid_document_path)
        yield f"data: {json.dumps({'stage': 'technical', 'result': tech_result})}\n\n"

        # 完成
        yield f"data: {json.dumps({'stage': 'complete'})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )

# ===== 4. 缓存策略 =====
@lru_cache(maxsize=100)
def get_regulation_embedding(regulation_text: str):
    """缓存法规嵌入向量"""
    return embedding_model.encode(regulation_text)
```

---

## 三、完整技术栈清单

### 3.1 核心依赖

```toml
# pyproject.toml
[project]
name = "bid-evaluation-assistant"
version = "1.0.0"
requires-python = ">=3.10"

dependencies = [
    # Web框架
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "pydantic>=2.10.0",

    # 文档解析
    "magic-pdf[full]>=0.7.0",  # MinerU
    "paddleocr>=2.8.0",
    "paddlepaddle-gpu>=3.0.0",

    # RAG
    "chromadb>=0.5.0",
    "flagembedding>=1.2.0",     # BGE
    "sentence-transformers>=3.0.0",

    # LLM
    "openai>=1.50.0",
    "dashscope>=1.20.0",        # 通义千问
    "zhipuai>=2.0.0",           # 智谱AI

    # Agent框架
    "langgraph>=0.2.0",
    "langchain>=0.3.0",
    "crewai>=0.80.0",

    # 评估
    "ragas>=0.1.0",
    "deepeval>=0.21.0",

    # 可观测性
    "langfuse>=2.0.0",
    "opentelemetry-api>=1.20.0",

    # 工具
    "httpx>=0.27.0",
    "tenacity>=9.0.0",          # 重试
    "orjson>=3.10.0",           # 快速JSON
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.6.0",
]
```

### 3.2 Docker部署

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# 安装Python依赖
COPY pyproject.toml .
RUN pip install --no-cache-dir -e .

# 复制应用代码
COPY src/ ./src/
COPY config/ ./config/

# 启动
CMD ["uvicorn", "src.web.app:app", "--host", "0.0.0.0", "--port", "8080"]
```

---

## 四、选型决策速查表

| 场景 | 推荐方案 | 备选方案 |
|------|----------|----------|
| **PDF解析** | MinerU 2.5 | PaddleOCR-VL |
| **中文Embedding** | BGE-M3 | BGE-large-zh |
| **向量数据库** | ChromaDB（开发）/ Milvus（生产） | Qdrant |
| **重排序** | BGE-Reranker-v2-m3 | Cohere API |
| **中文LLM** | Qwen 3 / DeepSeek-V3 | GLM-4.6 |
| **Agent框架** | LangGraph | CrewAI |
| **评估框架** | RAGAS + DeepEval | TruLens |
| **推理部署** | vLLM | TensorRT-LLM |
| **可观测性** | Langfuse（私有化）/ LangSmith | Arize Phoenix |
| **Web框架** | FastAPI + Pydantic v2 | - |

---

## 五、参考资料

### 5.1 核心论文
- [Searching for Best Practices in Retrieval-Augmented Generation](https://arxiv.org/abs/2407.01219) - 复旦大学RAG最佳实践研究

### 5.2 GitHub仓库
- [MinerU](https://github.com/opendatalab/MinerU) - 文档解析
- [FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding) - BGE系列
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent框架
- [vLLM](https://github.com/vllm-project/vllm) - 推理优化
- [RAGAS](https://github.com/explodinggradients/ragas) - RAG评估
- [DeepEval](https://github.com/confident-ai/deepeval) - LLM评估

### 5.3 文档
- [LangChain Production Best Practices](https://python.langchain.com/docs/production/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic V2](https://docs.pydantic.dev/latest/)

---

*文档版本：v1.0*
*更新时间：2026年2月20日*
