# MinerU è¾“å‡ºæ ¼å¼å¤„ç†ç ”ç©¶

> ç ”ç©¶æ—¥æœŸï¼š2026-02-20
> ç ”ç©¶é—®é¢˜ï¼šMinerU JSON ä¸èƒ½å¾ˆå¥½ä¿å­˜æ–‡æ¡£ç»“æ„ï¼ŒMarkdown æ— æ³•ä¿ç•™é¡µé¢ä½ç½®ä¿¡æ¯
> æ•°æ®æ¥æºï¼šWeb Searchã€Context7ã€å®˜æ–¹æ–‡æ¡£

---

## ä¸€ã€é—®é¢˜åˆ†æ

### 1.1 ä¸¤ç§è¾“å‡ºæ ¼å¼çš„ä¼˜ç¼ºç‚¹

| æ ¼å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| **JSON** (content_list.json) | âœ… åŒ…å« bbox åæ ‡ã€é¡µç ã€å—ç±»å‹<br>âœ… ä½ç½®ä¿¡æ¯å®Œæ•´ | âŒ æ–‡æ¡£ç»“æ„ä¸å¤Ÿç›´è§‚<br>âŒ è¡¨æ ¼/åˆ—è¡¨ç»“æ„éœ€è¦é¢å¤–å¤„ç† |
| **Markdown** | âœ… ä¿ç•™æ ‡é¢˜å±‚çº§ç»“æ„<br>âœ… è¡¨æ ¼/åˆ—è¡¨æ ¼å¼æ¸…æ™°<br>âœ… å¯è¯»æ€§å¼º | âŒ **æ— é¡µç ä¿¡æ¯**<br>âŒ **æ— ä½ç½®åæ ‡**<br>âŒ æº¯æºå›°éš¾ |

### 1.2 æ ¸å¿ƒçŸ›ç›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ ¸å¿ƒé—®é¢˜                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   JSON è¾“å‡º â”€â”€â”€â”€â”€â”€â†’ ä½ç½®ä¿¡æ¯ âœ…  ä½† ç»“æ„è¡¨è¾¾ âŒ              â”‚
â”‚                                                             â”‚
â”‚   MD è¾“å‡º â”€â”€â”€â”€â”€â”€â”€â”€â†’ ç»“æ„æ¸…æ™° âœ…  ä½† ä½ç½®ä¿¡æ¯ âŒ              â”‚
â”‚                                                             â”‚
â”‚   RAG ç³»ç»Ÿéœ€è¦ â”€â”€â”€â†’ ä¸¤è€…éƒ½è¦ï¼                              â”‚
â”‚                   â€¢ è¯­ä¹‰æ£€ç´¢éœ€è¦ç»“æ„åŒ–æ–‡æœ¬                   â”‚
â”‚                   â€¢ æº¯æºå¼•ç”¨éœ€è¦é¡µç /ä½ç½®                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€MinerU ä¸­é—´æ–‡ä»¶ç»“æ„åˆ†æ

### 2.1 middle.jsonï¼ˆä¸­é—´æ€æ–‡ä»¶ï¼‰

åŒ…å«å®Œæ•´çš„å—çº§åˆ«å…ƒæ•°æ®ï¼š

```json
{
  "blocks": [
    {
      "id": "block_001",
      "text": "æå–çš„æ–‡æœ¬å†…å®¹",
      "bbox": [x, y, width, height],
      "page": 1,
      "type": "text",
      "style": {
        "font": "Arial",
        "size": 12
      },
      "hierarchy": {
        "section": "1. å¼•è¨€",
        "level": 2
      }
    }
  ]
}
```

**å…³é”®å­—æ®µï¼š**
| å­—æ®µ | è¯´æ˜ | ç”¨é€” |
|------|------|------|
| `bbox` | è¾¹ç•Œæ¡†åæ ‡ [x, y, w, h] | ç²¾ç¡®å®šä½ |
| `page` | é¡µç  | æº¯æºå¼•ç”¨ |
| `type` | å—ç±»å‹ï¼ˆtext/table/image/formulaï¼‰ | åˆ†ç±»å¤„ç† |
| `hierarchy` | ç« èŠ‚å±‚çº§ | ç»“æ„ç†è§£ |

### 2.2 content_list.jsonï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰

```json
[
  {
    "text": "æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„æ·±åº¦å­¦ä¹ æ¶æ„...",
    "type": "text",
    "page_idx": 2,
    "bbox": [50, 200, 400, 350]
  }
]
```

---

## ä¸‰ã€è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šJSON + Metadata åˆ†ç¦»ï¼ˆæ¨è â­ï¼‰

**æ ¸å¿ƒæ€è·¯**ï¼šä½¿ç”¨ JSON çš„ä½ç½®ä¿¡æ¯ï¼ŒåŒæ—¶æå–ç»“æ„åŒ–å…ƒæ•°æ®

```python
from typing import List, Dict, Any
from pydantic import BaseModel

class ChunkMetadata(BaseModel):
    """åˆ†å—å…ƒæ•°æ®"""
    source: str           # æ–‡ä»¶è·¯å¾„
    page: int             # é¡µç 
    bbox: List[float]     # è¾¹ç•Œæ¡† [x0, y0, x1, y1]
    block_type: str       # å—ç±»å‹
    section: str = ""     # æ‰€å±ç« èŠ‚
    heading_path: List[str] = []  # æ ‡é¢˜è·¯å¾„

class DocumentChunk(BaseModel):
    """æ–‡æ¡£åˆ†å—"""
    content: str
    metadata: ChunkMetadata


def process_mineru_output(content_list: List[Dict], markdown: str) -> List[DocumentChunk]:
    """
    å¤„ç† MinerU è¾“å‡ºï¼Œåˆå¹¶ JSON ä½ç½®ä¿¡æ¯å’Œ Markdown ç»“æ„

    ç­–ç•¥ï¼š
    1. ä» JSON æå–ä½ç½®ä¿¡æ¯ï¼ˆbbox, pageï¼‰
    2. ä» Markdown æå–ç»“æ„ä¿¡æ¯ï¼ˆæ ‡é¢˜å±‚çº§ï¼‰
    3. åˆå¹¶ç”Ÿæˆå¸¦å®Œæ•´å…ƒæ•°æ®çš„åˆ†å—
    """
    chunks = []
    current_section = ""
    heading_stack = []

    for item in content_list:
        # æå–ä½ç½®ä¿¡æ¯
        metadata = ChunkMetadata(
            source=item.get("source", ""),
            page=item.get("page_idx", 0),
            bbox=item.get("bbox", [0, 0, 0, 0]),
            block_type=item.get("type", "text"),
            section=current_section,
            heading_path=heading_stack.copy()
        )

        chunk = DocumentChunk(
            content=item["text"],
            metadata=metadata
        )
        chunks.append(chunk)

        # æ›´æ–°æ ‡é¢˜æ ˆï¼ˆå¦‚æœæ£€æµ‹åˆ°æ ‡é¢˜ï¼‰
        if item.get("type") == "title":
            heading_stack.append(item["text"])
            current_section = item["text"]

    return chunks
```

### æ–¹æ¡ˆ Bï¼šç»“æ„æ„ŸçŸ¥åˆ†å—å™¨

**æ ¸å¿ƒæ€è·¯**ï¼šåœ¨åˆ†å—æ—¶ä¿ç•™ä½ç½®ä¿¡æ¯

```python
from typing import List, Tuple
import re

class StructureAwareChunker:
    """ç»“æ„æ„ŸçŸ¥åˆ†å—å™¨ - ä¿ç•™ä½ç½®ä¿¡æ¯"""

    def __init__(
        self,
        chunk_size: int = 512,
        overlap: int = 64,
        min_chunk_size: int = 100
    ):
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.min_chunk_size = min_chunk_size

    def chunk_with_positions(
        self,
        content_list: List[Dict]
    ) -> List[Dict[str, Any]]:
        """
        åˆ†å—å¹¶ä¿ç•™ä½ç½®ä¿¡æ¯

        è¾“å…¥: MinerU content_list.json
        è¾“å‡º: å¸¦ä½ç½®å…ƒæ•°æ®çš„åˆ†å—åˆ—è¡¨
        """
        chunks = []
        current_chunk = {
            "content": "",
            "positions": [],  # ä½ç½®åˆ—è¡¨
            "metadata": {}
        }

        for item in content_list:
            text = item.get("text", "")
            page = item.get("page_idx", 0)
            bbox = item.get("bbox", [0, 0, 0, 0])

            # ä½ç½®æ ‡ç­¾æ ¼å¼ï¼š@@{page}\t{x0}\t{x1}\t{top}\t{bottom}##
            position_tag = f"@@{page}\t{bbox[0]}\t{bbox[2]}\t{bbox[1]}\t{bbox[3]}##"

            # æ·»åŠ åˆ°å½“å‰åˆ†å—
            if len(current_chunk["content"]) + len(text) <= self.chunk_size:
                current_chunk["content"] += text + "\n"
                current_chunk["positions"].append({
                    "page": page,
                    "bbox": bbox,
                    "start": len(current_chunk["content"]) - len(text) - 1,
                    "end": len(current_chunk["content"]) - 1
                })
            else:
                # ä¿å­˜å½“å‰åˆ†å—
                if len(current_chunk["content"]) >= self.min_chunk_size:
                    chunks.append(current_chunk)

                # å¼€å§‹æ–°åˆ†å—ï¼ˆå¸¦ overlapï¼‰
                overlap_text = current_chunk["content"][-self.overlap:] if self.overlap > 0 else ""
                current_chunk = {
                    "content": overlap_text + text + "\n",
                    "positions": [{
                        "page": page,
                        "bbox": bbox,
                        "start": len(overlap_text),
                        "end": len(overlap_text) + len(text)
                    }],
                    "metadata": {
                        "source": item.get("source", ""),
                        "section": self._extract_section(item)
                    }
                }

        # ä¿å­˜æœ€åä¸€ä¸ªåˆ†å—
        if len(current_chunk["content"]) >= self.min_chunk_size:
            chunks.append(current_chunk)

        return chunks

    def _extract_section(self, item: Dict) -> str:
        """æå–ç« èŠ‚ä¿¡æ¯"""
        hierarchy = item.get("hierarchy", {})
        return hierarchy.get("section", "")

    @staticmethod
    def extract_positions(chunk_content: str) -> List[Dict]:
        """
        ä»åˆ†å—å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯

        æ ¼å¼ï¼š@@{page}\t{x0}\t{x1}\t{top}\t{bottom}##
        """
        pattern = r"@@(\d+)\t([\d.]+)\t([\d.]+)\t([\d.]+)\t([\d.]+)##"
        matches = re.findall(pattern, chunk_content)

        positions = []
        for match in matches:
            positions.append({
                "page": int(match[0]),
                "bbox": [float(match[1]), float(match[3]), float(match[2]), float(match[4])]
            })

        return positions
```

### æ–¹æ¡ˆ Cï¼šæ··åˆå­˜å‚¨ç­–ç•¥ï¼ˆDocling æ¨¡å¼ï¼‰

**å‚è€ƒ Docling çš„ DocChunk ç»“æ„ï¼š**

```python
from docling.chunking import DocChunk, DocChunkMetadata
from docling_core.types.doc.document import DoclingDocument

def process_with_docling(pdf_path: str) -> List[DocChunk]:
    """
    ä½¿ç”¨ Docling å¤„ç†ï¼Œè‡ªåŠ¨ä¿ç•™ä½ç½®å’Œç»“æ„
    """
    from docling.document_converter import DocumentConverter

    converter = DocumentConverter()
    result = converter.convert(pdf_path)

    # è·å–ç»“æ„åŒ–åˆ†å—
    chunker = HierarchicalChunker()
    doc_chunks = list(chunker.chunk(result.document))

    # æ¯ä¸ª chunk è‡ªåŠ¨åŒ…å«ï¼š
    # - text: æ–‡æœ¬å†…å®¹
    # - meta.headings: æ ‡é¢˜è·¯å¾„
    # - meta.doc_items[0].prov[0].page_no: é¡µç 
    # - meta.doc_items[0].prov[0].bbox: è¾¹ç•Œæ¡†

    return doc_chunks
```

**DocChunk è¾“å‡ºç¤ºä¾‹ï¼š**
```python
DocChunk(
    text="æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„æ·±åº¦å­¦ä¹ æ¶æ„...",
    meta=DocChunkMetadata(
        origin=Origin(filename="paper.pdf"),
        headings=["1. å¼•è¨€", "1.1 èƒŒæ™¯"],
        doc_items=[
            DocItem(
                prov=[
                    ProvenanceItem(
                        page_no=2,
                        bbox=Bbox(l=50, t=200, r=400, b=350)
                    )
                ]
            )
        ]
    )
)
```

---

## å››ã€æ¨èå®ç°æ–¹æ¡ˆ

### 4.1 æœ€ç»ˆæ¨èï¼šJSON + ä½ç½®æ ‡ç­¾æ³¨å…¥

**æ ¸å¿ƒæ€è·¯**ï¼šåœ¨ Markdown å†…å®¹ä¸­æ³¨å…¥ä½ç½®æ ‡ç­¾ï¼Œå®ç°ä¸¤å…¨å…¶ç¾

```python
import json
from pathlib import Path
from typing import List, Dict, Any

class MinerUProcessor:
    """MinerU è¾“å‡ºå¤„ç†å™¨"""

    def __init__(self, chunk_size: int = 512, overlap: int = 77):
        self.chunk_size = chunk_size  # ~512 tokens
        self.overlap = overlap         # ~15-20%

    def process(self, content_list_path: str) -> List[Dict[str, Any]]:
        """
        å¤„ç† MinerU content_list.json è¾“å‡º

        è¾“å‡ºæ ¼å¼ï¼š
        {
            "id": "chunk_001",
            "content": "æ–‡æœ¬å†…å®¹...",
            "metadata": {
                "source": "document.pdf",
                "pages": [1, 2],
                "positions": [
                    {"page": 1, "bbox": [50, 100, 400, 200]},
                    {"page": 2, "bbox": [50, 100, 400, 200]}
                ],
                "section": "1. å¼•è¨€",
                "heading_path": ["1. å¼•è¨€", "1.1 èƒŒæ™¯"],
                "chunk_type": "text"
            }
        }
        """
        with open(content_list_path, 'r', encoding='utf-8') as f:
            content_list = json.load(f)

        # æŒ‰é¡µç å’Œä½ç½®æ’åº
        sorted_items = sorted(
            content_list,
            key=lambda x: (x.get('page_idx', 0), x.get('bbox', [0])[1] if x.get('bbox') else 0)
        )

        chunks = []
        current_chunk = self._init_chunk()
        heading_stack = []

        for item in sorted_items:
            text = item.get('text', '').strip()
            if not text:
                continue

            page = item.get('page_idx', 0)
            bbox = item.get('bbox', [0, 0, 0, 0])
            item_type = item.get('type', 'text')

            # æ›´æ–°æ ‡é¢˜æ ˆ
            if item_type in ['title', 'section_header']:
                level = self._get_heading_level(item)
                # æˆªæ–­åˆ°å½“å‰å±‚çº§
                heading_stack = heading_stack[:level]
                heading_stack.append(text)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—
            if len(current_chunk['content']) + len(text) > self.chunk_size:
                if current_chunk['content']:
                    chunks.append(self._finalize_chunk(current_chunk))
                current_chunk = self._init_chunk(overlap_text=current_chunk['content'][-self.overlap:])

            # æ·»åŠ å†…å®¹
            current_chunk['content'] += text + '\n'
            current_chunk['positions'].append({
                'page': page,
                'bbox': bbox,
                'text_len': len(text)
            })
            current_chunk['pages'].add(page)
            current_chunk['heading_stack'] = heading_stack.copy()
            current_chunk['chunk_type'] = item_type

        # å¤„ç†æœ€åä¸€ä¸ªåˆ†å—
        if current_chunk['content'].strip():
            chunks.append(self._finalize_chunk(current_chunk))

        return chunks

    def _init_chunk(self, overlap_text: str = "") -> Dict:
        """åˆå§‹åŒ–æ–°åˆ†å—"""
        return {
            'content': overlap_text,
            'positions': [],
            'pages': set(),
            'heading_stack': [],
            'chunk_type': 'text'
        }

    def _finalize_chunk(self, chunk: Dict) -> Dict[str, Any]:
        """å®Œæˆåˆ†å—ï¼Œç”Ÿæˆæœ€ç»ˆæ ¼å¼"""
        return {
            'id': f"chunk_{len(chunk['content'])}_{hash(chunk['content'][:50])}",
            'content': chunk['content'].strip(),
            'metadata': {
                'pages': sorted(list(chunk['pages'])),
                'positions': chunk['positions'],
                'section': chunk['heading_stack'][-1] if chunk['heading_stack'] else '',
                'heading_path': chunk['heading_stack'],
                'chunk_type': chunk['chunk_type']
            }
        }

    def _get_heading_level(self, item: Dict) -> int:
        """è·å–æ ‡é¢˜å±‚çº§"""
        hierarchy = item.get('hierarchy', {})
        return hierarchy.get('level', 0)
```

### 4.2 ä½¿ç”¨ç¤ºä¾‹

```python
# åˆå§‹åŒ–å¤„ç†å™¨
processor = MinerUProcessor(
    chunk_size=512,   # ~512 tokens
    overlap=77        # ~15% overlap
)

# å¤„ç† MinerU è¾“å‡º
chunks = processor.process("output/content_list.json")

# å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
for chunk in chunks:
    # å­˜å‚¨æ—¶ä¿ç•™å®Œæ•´ metadata
    vector_store.add(
        text=chunk['content'],
        metadata=chunk['metadata'],
        id=chunk['id']
    )

# æ£€ç´¢æ—¶å¯ä»¥ç²¾ç¡®æº¯æº
results = vector_store.search(query="è¯„æ ‡æ ‡å‡†")

for result in results:
    print(f"å†…å®¹: {result.text[:100]}...")
    print(f"é¡µç : {result.metadata['pages']}")
    print(f"ç« èŠ‚: {result.metadata['section']}")
    print(f"ä½ç½®: {result.metadata['positions']}")
```

### 4.3 æº¯æºå¼•ç”¨è¾“å‡º

```python
def format_citation(chunk: Dict) -> str:
    """æ ¼å¼åŒ–æº¯æºå¼•ç”¨"""
    pages = chunk['metadata']['pages']
    section = chunk['metadata']['section']

    citation = f"ğŸ“„ æ¥æºï¼š{chunk['metadata'].get('source', 'æœªçŸ¥æ–‡æ¡£')}"
    if pages:
        citation += f"ï¼Œç¬¬ {', '.join(map(str, pages))} é¡µ"
    if section:
        citation += f"ï¼Œã€Œ{section}ã€"

    return citation

# ç¤ºä¾‹è¾“å‡ºï¼š
# ğŸ“„ æ¥æºï¼šæ‹›æ ‡æ–‡ä»¶.pdfï¼Œç¬¬ 5, 6 é¡µï¼Œã€Œ2.2 æŠ€æœ¯è¯„å®¡æ ‡å‡†ã€
```

---

## äº”ã€RAGFlow / Docling å¯¹æ¯”

### 5.1 ä½ç½®æ ‡ç­¾ç”Ÿæˆå¯¹æ¯”

| æ¡†æ¶ | ä½ç½®æ ¼å¼ | ä¿ç•™ä¿¡æ¯ |
|------|----------|----------|
| **RAGFlow** | `@@{page}\t{x0}\t{x1}\t{top}\t{bottom}##` | é¡µç  + bbox |
| **Docling** | `ProvenanceItem(page_no, bbox)` | é¡µç  + bbox + ç½®ä¿¡åº¦ |
| **MinerU JSON** | `{"page_idx": N, "bbox": [...]}` | é¡µç  + bbox |

### 5.2 æ¨èç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ–‡æ¡£å¤„ç†æµç¨‹                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   PDF æ–‡æ¡£                                                  â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚              MinerU è§£æ                             â”‚  â”‚
â”‚   â”‚  è¾“å‡ºï¼šcontent_list.json + content_list.md          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚          MinerUProcessor å¤„ç†                        â”‚  â”‚
â”‚   â”‚  1. ä» JSON æå–ä½ç½®ä¿¡æ¯ (page, bbox)                â”‚  â”‚
â”‚   â”‚  2. æŒ‰ç»“æ„åˆ†å—ï¼Œä¿ç•™æ ‡é¢˜å±‚çº§                          â”‚  â”‚
â”‚   â”‚  3. æ¯ä¸ª chunk æºå¸¦å®Œæ•´ metadata                     â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚            LightRAG å­˜å‚¨                             â”‚  â”‚
â”‚   â”‚  â€¢ å‘é‡ç´¢å¼•ï¼šcontent embedding                       â”‚  â”‚
â”‚   â”‚  â€¢ å…ƒæ•°æ®è¿‡æ»¤ï¼špage, section                         â”‚  â”‚
â”‚   â”‚  â€¢ æº¯æºå¼•ç”¨ï¼špositions                               â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å…­ã€æœ€ä½³å®è·µæ€»ç»“

### 6.1 å…³é”®åŸåˆ™

| åŸåˆ™ | è¯´æ˜ |
|------|------|
| **ä¿ç•™åŸå§‹ JSON** | JSON åŒ…å«å®Œæ•´çš„ä½ç½®ä¿¡æ¯ï¼Œæ˜¯æº¯æºçš„åŸºç¡€ |
| **ç»“æ„æ„ŸçŸ¥åˆ†å—** | æŒ‰æ–‡æ¡£ç»“æ„ï¼ˆæ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ï¼‰åˆ†å—ï¼Œè€Œéå›ºå®šé•¿åº¦ |
| **å…ƒæ•°æ®ç»§æ‰¿** | æ¯ä¸ªåˆ†å—å¿…é¡»ç»§æ‰¿çˆ¶æ–‡æ¡£çš„å…ƒæ•°æ® |
| **ä½ç½®æ ‡ç­¾æ³¨å…¥** | å¯é€‰ï¼šåœ¨å†…å®¹ä¸­æ³¨å…¥ä½ç½®æ ‡ç­¾ï¼Œå®ç°ç²¾ç¡®æº¯æº |

### 6.2 Chunk ç»“æ„è§„èŒƒ

```python
{
    "id": "chunk_xxx",
    "content": "æ–‡æœ¬å†…å®¹...",
    "metadata": {
        # å¿…éœ€å­—æ®µ
        "source": "document.pdf",      # æºæ–‡ä»¶
        "pages": [1, 2],               # é¡µç åˆ—è¡¨

        # ä½ç½®ä¿¡æ¯
        "positions": [
            {"page": 1, "bbox": [x0, y0, x1, y1]}
        ],

        # ç»“æ„ä¿¡æ¯
        "section": "2.2 æŠ€æœ¯è¯„å®¡æ ‡å‡†",  # å½“å‰ç« èŠ‚
        "heading_path": ["2. è¯„å®¡", "2.2 æŠ€æœ¯è¯„å®¡æ ‡å‡†"],  # æ ‡é¢˜è·¯å¾„

        # ç±»å‹ä¿¡æ¯
        "chunk_type": "text",          # text/table/image/formula
        "language": "zh"
    }
}
```

### 6.3 åˆ†å—é…ç½®å»ºè®®

| æ–‡æ¡£ç±»å‹ | Chunk Size | Overlap | ç‰¹æ®Šå¤„ç† |
|----------|------------|---------|----------|
| **æ‹›æŠ•æ ‡æ–‡æ¡£** | 512 tokens | 15-20% | ä¿ç•™è¡¨æ ¼å®Œæ•´æ€§ |
| æŠ€æœ¯å‚æ•°è¡¨ | æŒ‰è¡¨æ ¼ | 0% | æ•´è¡¨ä½œä¸ºä¸€ä¸ª chunk |
| åˆåŒ/æ³•å¾‹ | 256-512 | 20% | æŒ‰æ¡æ¬¾åˆ†å— |
| èµ„è´¨è¯ä¹¦ | æŒ‰é¡¹ | 0% | è¯ä¹¦ä¿¡æ¯å®Œæ•´ä¿ç•™ |

---

## ä¸ƒã€å‚è€ƒèµ„æ–™

**MinerU ç›¸å…³ï¼š**
- [MinerU é¡¹ç›®åœ°å€](https://github.com/opendatalab/MinerU)
- [MinerU ç»ˆææŒ‡å—](https://m.blog.csdn.net/gitblog_00575/article/details/156704229)
- [MinerU æ–‡æ¡£ä½“ç³»è§£æ](https://m.blog.csdn.net/gitblog_00611/article/details/151142665)

**RAG åˆ†å—æœ€ä½³å®è·µï¼š**
- [RAG æ–‡æ¡£åˆ†å—ç­–ç•¥è¯¦è§£](https://juejin.cn/post/7607358297457098752)
- [ä» Markdown åˆ°å‘é‡çŸ¥è¯†åº“](https://m.blog.csdn.net/weixin_47420447/article/details/150967394)
- [RAG å…ƒæ•°æ®ç®¡ç†å®è·µ](https://m.blog.csdn.net/weixin_65416248/article/details/157845039)

**Docling å‚è€ƒï¼š**
- [Docling å®˜æ–¹æ–‡æ¡£](https://docling-project.github.io/docling/)
- [Docling è§†è§‰å®šä½](https://blog.csdn.net/gitblog_00972/article/details/151146670)

---

*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*
*åˆ›å»ºæ—¥æœŸï¼š2026-02-20*
