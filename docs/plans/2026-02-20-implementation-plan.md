# è¾…åŠ©è¯„æ ‡ä¸“å®¶ç³»ç»Ÿå®ç°è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** æ„å»ºä¸€ä¸ªåŸºäº Agentic RAG çš„åŒ»ç–—å™¨æ¢°æ‹›æŠ•æ ‡è¾…åŠ©è¯„æ ‡ç³»ç»Ÿï¼Œå®ç°æŠ•æ ‡æ–‡ä»¶æ™ºèƒ½è§£æã€åˆè§„æ€§è‡ªåŠ¨å®¡æŸ¥ã€æ™ºèƒ½è¯„åˆ†å»ºè®®ã€‚

**Architecture:** åˆ†å±‚å•ä½“æ¶æ„ï¼Œåç«¯ FastAPI + å‰ç«¯ Vue3ï¼Œä½¿ç”¨ LangGraph æ„å»º Agent å·¥ä½œæµï¼ŒChromaDB ä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒ LLM å¤š Provider åˆ‡æ¢ã€‚

**Tech Stack:** Python 3.11, FastAPI, Pydantic v2, LangGraph, LangChain, ChromaDB, BGE-M3, Vue3, Element Plus

---

## é˜¶æ®µä¸€ï¼šé¡¹ç›®åˆå§‹åŒ–ä¸åŸºç¡€RAGï¼ˆWeek 1-2ï¼‰

### Task 1: åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„

**Files:**
- Create: `backend/`
- Create: `backend/src/`
- Create: `backend/src/__init__.py`
- Create: `backend/src/core/`
- Create: `backend/src/core/__init__.py`
- Create: `backend/tests/`
- Create: `backend/pyproject.toml`
- Create: `backend/.env.example`

**Step 1: åˆ›å»ºç›®å½•ç»“æ„**

```bash
mkdir -p backend/src/{core,api,services,agents,rag,document,models}
mkdir -p backend/tests/{unit,integration}
mkdir -p backend/config/agents
mkdir -p data/{uploads,parsed,knowledge_base}
touch backend/src/__init__.py
touch backend/src/core/__init__.py
touch backend/src/api/__init__.py
touch backend/src/services/__init__.py
touch backend/src/agents/__init__.py
touch backend/src/rag/__init__.py
touch backend/src/document/__init__.py
touch backend/src/models/__init__.py
```

**Step 2: åˆ›å»º pyproject.toml**

```toml
# backend/pyproject.toml
[project]
name = "bid-evaluation-assistant"
version = "1.0.0"
description = "è¾…åŠ©è¯„æ ‡ä¸“å®¶ç³»ç»Ÿ - åŸºäºAgentic RAGçš„æ™ºèƒ½è¯„æ ‡åŠ©æ‰‹"
requires-python = ">=3.11"
readme = "README.md"

dependencies = [
    # Webæ¡†æ¶
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "pydantic>=2.10.0",
    "pydantic-settings>=2.6.0",

    # æ•°æ®åº“
    "sqlalchemy>=2.0.0",
    "asyncpg>=0.30.0",
    "alembic>=1.14.0",

    # å‘é‡æ•°æ®åº“
    "chromadb>=0.5.0",

    # LLMæ¡†æ¶
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",
    "langchain-community>=0.3.0",
    "langgraph>=0.2.0",

    # Embedding
    "sentence-transformers>=3.0.0",

    # å·¥å…·
    "httpx>=0.27.0",
    "tenacity>=9.0.0",
    "orjson>=3.10.0",
    "pyyaml>=6.0",
    "python-multipart>=0.0.17",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",

    # æ–‡æ¡£å¤„ç†
    "pypdf>=5.0.0",

    # å¯è§‚æµ‹æ€§
    "langfuse>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "pytest-cov>=5.0.0",
    "ruff>=0.6.0",
    "mypy>=1.11.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.11"
strict = true
ignore_missing_imports = true
```

**Step 3: åˆ›å»º .env.example**

```env
# backend/.env.example
# åº”ç”¨é…ç½®
APP_NAME=bid-evaluation-assistant
APP_ENV=development
DEBUG=true
SECRET_KEY=your-secret-key-change-in-production

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/bid_eval

# ChromaDBé…ç½®
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_PERSIST_DIR=./data/chroma

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0

# LLMé…ç½® - DeepSeek
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_BASE_URL=https://api.deepseek.com

# LLMé…ç½® - Qwen
QWEN_API_KEY=your-qwen-api-key
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# Langfuseé…ç½®ï¼ˆå¯è§‚æµ‹æ€§ï¼‰
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_SECRET_KEY=your-langfuse-secret-key
LANGFUSE_HOST=http://localhost:3000

# æ–‡ä»¶å­˜å‚¨
UPLOAD_DIR=./data/uploads
PARSED_DIR=./data/parsed
```

**Step 4: Commit**

```bash
git add backend/ data/
git commit -m "feat: åˆå§‹åŒ–åç«¯é¡¹ç›®ç»“æ„

- åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
- æ·»åŠ  pyproject.toml ä¾èµ–é…ç½®
- æ·»åŠ  .env.example ç¯å¢ƒå˜é‡æ¨¡æ¿"
```

---

### Task 2: å®ç°æ ¸å¿ƒé…ç½®æ¨¡å—

**Files:**
- Create: `backend/src/core/config.py`
- Create: `backend/tests/unit/test_config.py`

**Step 1: å†™å¤±è´¥çš„æµ‹è¯•**

```python
# backend/tests/unit/test_config.py
import os
import pytest
from pydantic import ValidationError


def test_settings_default_values():
    """æµ‹è¯•é»˜è®¤é…ç½®å€¼"""
    from src.core.config import Settings

    # è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡
    os.environ["SECRET_KEY"] = "test-secret-key"
    os.environ["DATABASE_URL"] = "postgresql+asyncpg://test:test@localhost:5432/test"

    settings = Settings()

    assert settings.APP_NAME == "bid-evaluation-assistant"
    assert settings.APP_ENV == "development"
    assert settings.DEBUG is True


def test_settings_requires_secret_key():
    """æµ‹è¯• SECRET_KEY æ˜¯å¿…éœ€çš„"""
    # æ¸…é™¤ç¯å¢ƒå˜é‡
    if "SECRET_KEY" in os.environ:
        del os.environ["SECRET_KEY"]

    with pytest.raises(ValidationError):
        from src.core.config import Settings
        Settings()


def test_llm_config():
    """æµ‹è¯• LLM é…ç½®"""
    os.environ["SECRET_KEY"] = "test-secret-key"
    os.environ["DATABASE_URL"] = "postgresql+asyncpg://test:test@localhost:5432/test"
    os.environ["DEEPSEEK_API_KEY"] = "test-deepseek-key"

    from src.core.config import Settings

    settings = Settings()

    assert settings.DEEPSEEK_API_KEY == "test-deepseek-key"
    assert settings.DEEPSEEK_BASE_URL == "https://api.deepseek.com"
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

```bash
cd backend && python -m pytest tests/unit/test_config.py -v
```

Expected: FAIL (ModuleNotFoundError)

**Step 3: å®ç°é…ç½®æ¨¡å—**

```python
# backend/src/core/config.py
"""
æ ¸å¿ƒé…ç½®æ¨¡å—
ä½¿ç”¨ pydantic-settings ç®¡ç†ç¯å¢ƒå˜é‡å’Œé…ç½®
"""
from functools import lru_cache
from typing import Optional

from pydantic import Field, field_validator
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=True,
        extra="ignore",
    )

    # åº”ç”¨é…ç½®
    APP_NAME: str = "bid-evaluation-assistant"
    APP_ENV: str = Field(default="development", pattern="^(development|staging|production)$")
    DEBUG: bool = True
    SECRET_KEY: str  # å¿…éœ€ï¼Œæ— é»˜è®¤å€¼

    # APIé…ç½®
    API_PREFIX: str = "/api/v1"

    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str  # å¿…éœ€

    # ChromaDBé…ç½®
    CHROMA_HOST: str = "localhost"
    CHROMA_PORT: int = 8000
    CHROMA_PERSIST_DIR: str = "./data/chroma"

    # Redisé…ç½®
    REDIS_URL: str = "redis://localhost:6379/0"

    # LLMé…ç½® - DeepSeek
    DEEPSEEK_API_KEY: Optional[str] = None
    DEEPSEEK_BASE_URL: str = "https://api.deepseek.com"

    # LLMé…ç½® - Qwen (é€šä¹‰åƒé—®)
    QWEN_API_KEY: Optional[str] = None
    QWEN_BASE_URL: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"

    # LLMé…ç½® - OpenAIå…¼å®¹
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_BASE_URL: Optional[str] = None

    # Langfuseé…ç½®ï¼ˆå¯è§‚æµ‹æ€§ï¼‰
    LANGFUSE_PUBLIC_KEY: Optional[str] = None
    LANGFUSE_SECRET_KEY: Optional[str] = None
    LANGFUSE_HOST: str = "http://localhost:3000"

    # æ–‡ä»¶å­˜å‚¨
    UPLOAD_DIR: str = "./data/uploads"
    PARSED_DIR: str = "./data/parsed"
    MAX_UPLOAD_SIZE: int = 100 * 1024 * 1024  # 100MB

    # JWTé…ç½®
    JWT_ALGORITHM: str = "HS256"
    JWT_EXPIRE_MINUTES: int = 60 * 24  # 24å°æ—¶

    # Agenté…ç½®
    DEFAULT_LLM_PROVIDER: str = "deepseek"
    CONFIDENCE_THRESHOLD: float = 0.75
    MAX_ITERATIONS: int = 5

    @field_validator("DEBUG", mode="before")
    @classmethod
    def parse_debug(cls, v: str | bool) -> bool:
        if isinstance(v, bool):
            return v
        return v.lower() in ("true", "1", "yes")


@lru_cache
def get_settings() -> Settings:
    """è·å–é…ç½®å•ä¾‹"""
    return Settings()


# å¯¼å‡ºä¾¿æ·è®¿é—®
settings = get_settings()
```

**Step 4: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

```bash
cd backend && python -m pytest tests/unit/test_config.py -v
```

Expected: PASS

**Step 5: Commit**

```bash
git add backend/src/core/config.py backend/tests/unit/test_config.py
git commit -m "feat: å®ç°æ ¸å¿ƒé…ç½®æ¨¡å—

- ä½¿ç”¨ pydantic-settings ç®¡ç†ç¯å¢ƒå˜é‡
- æ”¯æŒ DeepSeekã€Qwenã€OpenAI å¤š LLM é…ç½®
- æ·»åŠ é…ç½®å•å…ƒæµ‹è¯•"
```

---

### Task 3: å®ç° LLM æœåŠ¡æŠ½è±¡å±‚

**Files:**
- Create: `backend/src/services/llm/`
- Create: `backend/src/services/llm/__init__.py`
- Create: `backend/src/services/llm/base.py`
- Create: `backend/src/services/llm/providers.py`
- Create: `backend/src/services/llm/gateway.py`
- Create: `backend/tests/unit/test_llm_gateway.py`

**Step 1: å†™å¤±è´¥çš„æµ‹è¯•**

```python
# backend/tests/unit/test_llm_gateway.py
import pytest
from unittest.mock import AsyncMock, patch


@pytest.mark.asyncio
async def test_llm_gateway_get_provider():
    """æµ‹è¯•è·å– Provider"""
    from src.services.llm.gateway import LLMGateway

    gateway = LLMGateway()
    provider = gateway.get_provider("deepseek")

    assert provider is not None
    assert provider.name == "deepseek"


@pytest.mark.asyncio
async def test_llm_gateway_chat():
    """æµ‹è¯•èŠå¤©æ¥å£"""
    from src.services.llm.gateway import LLMGateway

    gateway = LLMGateway()

    # Mock LLM å“åº”
    with patch.object(gateway, "chat", new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”"

        response = await gateway.chat(
            provider="deepseek",
            model="deepseek-chat",
            messages=[{"role": "user", "content": "ä½ å¥½"}]
        )

        assert response == "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”"


@pytest.mark.asyncio
async def test_llm_provider_not_found():
    """æµ‹è¯• Provider ä¸å­˜åœ¨"""
    from src.services.llm.gateway import LLMGateway

    gateway = LLMGateway()

    with pytest.raises(ValueError, match="Provider not found"):
        gateway.get_provider("nonexistent")
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

```bash
cd backend && python -m pytest tests/unit/test_llm_gateway.py -v
```

Expected: FAIL (ModuleNotFoundError)

**Step 3: å®ç° LLM æŠ½è±¡å±‚åŸºç±»**

```python
# backend/src/services/llm/base.py
"""
LLM Provider æŠ½è±¡åŸºç±»
"""
from abc import ABC, abstractmethod
from typing import AsyncIterator, List, Optional


class BaseLLMProvider(ABC):
    """LLM Provider æŠ½è±¡åŸºç±»"""

    def __init__(
        self,
        name: str,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
    ):
        self.name = name
        self.api_key = api_key
        self.base_url = base_url

    @abstractmethod
    async def chat(
        self,
        messages: List[dict],
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> str:
        """åŒæ­¥èŠå¤©æ¥å£"""
        pass

    @abstractmethod
    async def stream(
        self,
        messages: List[dict],
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> AsyncIterator[str]:
        """æµå¼èŠå¤©æ¥å£"""
        pass

    def is_available(self) -> bool:
        """æ£€æŸ¥ Provider æ˜¯å¦å¯ç”¨"""
        return self.api_key is not None
```

**Step 4: å®ç° Provider å®ç°**

```python
# backend/src/services/llm/providers.py
"""
å…·ä½“çš„ LLM Provider å®ç°
"""
import os
from typing import AsyncIterator, List, Optional

from langchain_openai import ChatOpenAI

from .base import BaseLLMProvider


class OpenAICompatibleProvider(BaseLLMProvider):
    """OpenAI å…¼å®¹çš„ Providerï¼ˆæ”¯æŒ DeepSeekã€Qwenã€OpenAIï¼‰"""

    def __init__(
        self,
        name: str,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        default_model: str = "gpt-4o-mini",
    ):
        super().__init__(name, api_key, base_url)
        self.default_model = default_model
        self._client: Optional[ChatOpenAI] = None

    def _get_client(self, model: str, temperature: float, max_tokens: int) -> ChatOpenAI:
        """è·å–æˆ–åˆ›å»º LangChain ChatOpenAI å®¢æˆ·ç«¯"""
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            api_key=self.api_key,
            base_url=self.base_url,
        )

    async def chat(
        self,
        messages: List[dict],
        model: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> str:
        """åŒæ­¥èŠå¤©æ¥å£"""
        if not self.is_available():
            raise ValueError(f"Provider {self.name} is not available: missing API key")

        model = model or self.default_model
        client = self._get_client(model, temperature, max_tokens)

        from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

        lc_messages = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")

            if role == "system":
                lc_messages.append(SystemMessage(content=content))
            elif role == "assistant":
                lc_messages.append(AIMessage(content=content))
            else:
                lc_messages.append(HumanMessage(content=content))

        response = await client.ainvoke(lc_messages)
        return response.content

    async def stream(
        self,
        messages: List[dict],
        model: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> AsyncIterator[str]:
        """æµå¼èŠå¤©æ¥å£"""
        if not self.is_available():
            raise ValueError(f"Provider {self.name} is not available: missing API key")

        model = model or self.default_model
        client = self._get_client(model, temperature, max_tokens)

        from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

        lc_messages = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")

            if role == "system":
                lc_messages.append(SystemMessage(content=content))
            elif role == "assistant":
                lc_messages.append(AIMessage(content=content))
            else:
                lc_messages.append(HumanMessage(content=content))

        async for chunk in client.astream(lc_messages):
            if chunk.content:
                yield chunk.content


class DeepSeekProvider(OpenAICompatibleProvider):
    """DeepSeek Provider"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        super().__init__(
            name="deepseek",
            api_key=api_key,
            base_url=base_url or "https://api.deepseek.com",
            default_model="deepseek-chat",
        )


class QwenProvider(OpenAICompatibleProvider):
    """Qwen (é€šä¹‰åƒé—®) Provider"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        super().__init__(
            name="qwen",
            api_key=api_key,
            base_url=base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1",
            default_model="qwen-turbo",
        )


class OpenAIProvider(OpenAICompatibleProvider):
    """OpenAI Provider"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        super().__init__(
            name="openai",
            api_key=api_key,
            base_url=base_url,
            default_model="gpt-4o-mini",
        )
```

**Step 5: å®ç° LLM Gateway**

```python
# backend/src/services/llm/gateway.py
"""
LLM Gateway - ç»Ÿä¸€çš„ LLM è®¿é—®å…¥å£
æ”¯æŒå¤š Provider åˆ‡æ¢ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœè½¬ç§»
"""
from typing import AsyncIterator, Dict, List, Optional

from src.core.config import settings

from .base import BaseLLMProvider
from .providers import DeepSeekProvider, OpenAIProvider, QwenProvider


class LLMGateway:
    """
    LLM Gateway

    ç»Ÿä¸€çš„ LLM è®¿é—®å…¥å£ï¼Œæ”¯æŒï¼š
    - å¤š Provider ç®¡ç†
    - åŠ¨æ€ Provider åˆ‡æ¢
    - æŒ‰éœ€åˆ›å»º Provider å®ä¾‹
    """

    def __init__(self):
        self._providers: Dict[str, BaseLLMProvider] = {}
        self._init_providers()

    def _init_providers(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„ Provider"""
        # DeepSeek
        if settings.DEEPSEEK_API_KEY:
            self._providers["deepseek"] = DeepSeekProvider(
                api_key=settings.DEEPSEEK_API_KEY,
                base_url=settings.DEEPSEEK_BASE_URL,
            )

        # Qwen
        if settings.QWEN_API_KEY:
            self._providers["qwen"] = QwenProvider(
                api_key=settings.QWEN_API_KEY,
                base_url=settings.QWEN_BASE_URL,
            )

        # OpenAI
        if settings.OPENAI_API_KEY:
            self._providers["openai"] = OpenAIProvider(
                api_key=settings.OPENAI_API_KEY,
                base_url=settings.OPENAI_BASE_URL,
            )

    def get_provider(self, name: str) -> BaseLLMProvider:
        """è·å–æŒ‡å®š Provider"""
        if name not in self._providers:
            raise ValueError(f"Provider not found: {name}")
        return self._providers[name]

    def list_providers(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Provider"""
        return list(self._providers.keys())

    async def chat(
        self,
        messages: List[dict],
        provider: Optional[str] = None,
        model: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> str:
        """
        èŠå¤©æ¥å£

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            provider: Provider åç§°ï¼Œé»˜è®¤ä½¿ç”¨ DEFAULT_LLM_PROVIDER
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ token æ•°

        Returns:
            æ¨¡å‹å“åº”æ–‡æœ¬
        """
        provider_name = provider or settings.DEFAULT_LLM_PROVIDER
        provider_instance = self.get_provider(provider_name)

        return await provider_instance.chat(
            messages=messages,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )

    async def stream(
        self,
        messages: List[dict],
        provider: Optional[str] = None,
        model: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        **kwargs,
    ) -> AsyncIterator[str]:
        """
        æµå¼èŠå¤©æ¥å£
        """
        provider_name = provider or settings.DEFAULT_LLM_PROVIDER
        provider_instance = self.get_provider(provider_name)

        async for chunk in provider_instance.stream(
            messages=messages,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        ):
            yield chunk


# å…¨å±€å•ä¾‹
_gateway: Optional[LLMGateway] = None


def get_gateway() -> LLMGateway:
    """è·å– LLM Gateway å•ä¾‹"""
    global _gateway
    if _gateway is None:
        _gateway = LLMGateway()
    return _gateway
```

**Step 6: åˆ›å»º __init__.py**

```python
# backend/src/services/llm/__init__.py
"""
LLM æœåŠ¡æ¨¡å—
"""
from .base import BaseLLMProvider
from .gateway import LLMGateway, get_gateway
from .providers import DeepSeekProvider, OpenAIProvider, QwenProvider

__all__ = [
    "BaseLLMProvider",
    "LLMGateway",
    "get_gateway",
    "DeepSeekProvider",
    "OpenAIProvider",
    "QwenProvider",
]
```

**Step 7: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

```bash
cd backend && python -m pytest tests/unit/test_llm_gateway.py -v
```

Expected: PASS

**Step 8: Commit**

```bash
git add backend/src/services/llm/ backend/tests/unit/test_llm_gateway.py
git commit -m "feat: å®ç° LLM æœåŠ¡æŠ½è±¡å±‚

- æ·»åŠ  BaseLLMProvider æŠ½è±¡åŸºç±»
- å®ç° DeepSeekã€Qwenã€OpenAI Provider
- å®ç° LLMGateway ç»Ÿä¸€è®¿é—®å…¥å£
- æ”¯æŒåŒæ­¥å’Œæµå¼å“åº”"
```

---

### Task 4: å®ç° FastAPI åº”ç”¨å…¥å£

**Files:**
- Create: `backend/src/main.py`
- Create: `backend/src/api/__init__.py`
- Create: `backend/src/api/health.py`
- Create: `backend/tests/unit/test_api.py`

**Step 1: å†™å¤±è´¥çš„æµ‹è¯•**

```python
# backend/tests/unit/test_api.py
import pytest
from httpx import AsyncClient, ASGITransport


@pytest.mark.asyncio
async def test_health_check():
    """æµ‹è¯•å¥åº·æ£€æŸ¥æ¥å£"""
    from src.main import app

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as client:
        response = await client.get("/api/v1/health")

    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert "version" in data


@pytest.mark.asyncio
async def test_openapi_docs():
    """æµ‹è¯• OpenAPI æ–‡æ¡£å¯è®¿é—®"""
    from src.main import app

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as client:
        response = await client.get("/docs")

    assert response.status_code == 200
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

```bash
cd backend && python -m pytest tests/unit/test_api.py -v
```

Expected: FAIL

**Step 3: å®ç°å¥åº·æ£€æŸ¥ API**

```python
# backend/src/api/health.py
"""
å¥åº·æ£€æŸ¥ API
"""
from fastapi import APIRouter

from src.core.config import settings

router = APIRouter(tags=["Health"])


@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "app_name": settings.APP_NAME,
        "version": "1.0.0",
        "environment": settings.APP_ENV,
    }
```

**Step 4: å®ç°ä¸»åº”ç”¨å…¥å£**

```python
# backend/src/main.py
"""
FastAPI åº”ç”¨å…¥å£
"""
from contextlib import asynccontextmanager

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from src.api.health import router as health_router
from src.core.config import settings


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    print(f"ğŸš€ {settings.APP_NAME} starting...")
    yield
    # å…³é—­æ—¶
    print(f"ğŸ‘‹ {settings.APP_NAME} shutting down...")


def create_app() -> FastAPI:
    """åˆ›å»º FastAPI åº”ç”¨"""
    app = FastAPI(
        title=settings.APP_NAME,
        description="è¾…åŠ©è¯„æ ‡ä¸“å®¶ç³»ç»Ÿ - åŸºäºAgentic RAGçš„æ™ºèƒ½è¯„æ ‡åŠ©æ‰‹",
        version="1.0.0",
        docs_url="/docs",
        redoc_url="/redoc",
        openapi_url="/openapi.json",
        lifespan=lifespan,
    )

    # CORS ä¸­é—´ä»¶
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒéœ€è¦é…ç½®å…·ä½“åŸŸå
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # æ³¨å†Œè·¯ç”±
    app.include_router(health_router, prefix=settings.API_PREFIX)

    return app


# åˆ›å»ºåº”ç”¨å®ä¾‹
app = create_app()


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG,
    )
```

**Step 5: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

```bash
cd backend && python -m pytest tests/unit/test_api.py -v
```

Expected: PASS

**Step 6: Commit**

```bash
git add backend/src/main.py backend/src/api/ backend/tests/unit/test_api.py
git commit -m "feat: å®ç° FastAPI åº”ç”¨å…¥å£

- æ·»åŠ å¥åº·æ£€æŸ¥ API
- é…ç½® CORS ä¸­é—´ä»¶
- æ”¯æŒå¼€å‘æ¨¡å¼çƒ­é‡è½½"
```

---

### Task 5: å®ç°å‘é‡å­˜å‚¨æœåŠ¡

**Files:**
- Create: `backend/src/rag/__init__.py`
- Create: `backend/src/rag/embeddings.py`
- Create: `backend/src/rag/vectorstore.py`
- Create: `backend/tests/unit/test_vectorstore.py`

**Step 1: å†™å¤±è´¥çš„æµ‹è¯•**

```python
# backend/tests/unit/test_vectorstore.py
import pytest
from unittest.mock import Mock, patch


def test_embedding_model_initialization():
    """æµ‹è¯• Embedding æ¨¡å‹åˆå§‹åŒ–"""
    from src.rag.embeddings import EmbeddingService

    with patch("src.rag.embeddings.SentenceTransformer") as mock_transformer:
        mock_transformer.return_value = Mock()

        service = EmbeddingService()

        assert service.model is not None


def test_embedding_encode():
    """æµ‹è¯•æ–‡æœ¬ç¼–ç """
    from src.rag.embeddings import EmbeddingService

    with patch("src.rag.embeddings.SentenceTransformer") as mock_transformer:
        mock_model = Mock()
        mock_model.encode.return_value = [[0.1, 0.2, 0.3]]
        mock_transformer.return_value = mock_model

        service = EmbeddingService()
        embeddings = service.encode(["æµ‹è¯•æ–‡æœ¬"])

        assert len(embeddings) == 1
        assert len(embeddings[0]) == 3


@pytest.mark.asyncio
async def test_vectorstore_add_documents():
    """æµ‹è¯•æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
    from src.rag.vectorstore import VectorStoreService

    with patch("src.rag.vectorstore.Chroma") as mock_chroma:
        mock_collection = Mock()
        mock_chroma.return_value = mock_collection

        service = VectorStoreService()

        # è¿™ä¸ªæµ‹è¯•éªŒè¯æ¥å£å­˜åœ¨
        assert service is not None
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

```bash
cd backend && python -m pytest tests/unit/test_vectorstore.py -v
```

Expected: FAIL

**Step 3: å®ç° Embedding æœåŠ¡**

```python
# backend/src/rag/embeddings.py
"""
Embedding æœåŠ¡
ä½¿ç”¨ sentence-transformers æä¾›æ–‡æœ¬å‘é‡åŒ–èƒ½åŠ›
"""
from typing import List, Optional

from sentence_transformers import SentenceTransformer

from src.core.config import settings


class EmbeddingService:
    """
    Embedding æœåŠ¡

    ä½¿ç”¨ BGE ç³»åˆ—æ¨¡å‹è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
    """

    # é»˜è®¤ä½¿ç”¨ BGE-small-zhï¼ˆè½»é‡çº§ä¸­æ–‡æ¨¡å‹ï¼‰
    DEFAULT_MODEL = "BAAI/bge-small-zh-v1.5"

    def __init__(self, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ– Embedding æœåŠ¡

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ BGE-small-zh
        """
        self.model_name = model_name or self.DEFAULT_MODEL
        self._model: Optional[SentenceTransformer] = None

    @property
    def model(self) -> SentenceTransformer:
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        if self._model is None:
            self._model = SentenceTransformer(self.model_name)
        return self._model

    def encode(
        self,
        texts: List[str],
        normalize_embeddings: bool = True,
    ) -> List[List[float]]:
        """
        å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            normalize_embeddings: æ˜¯å¦å½’ä¸€åŒ–å‘é‡

        Returns:
            å‘é‡åˆ—è¡¨
        """
        embeddings = self.model.encode(
            texts,
            normalize_embeddings=normalize_embeddings,
            convert_to_numpy=True,
        )
        return embeddings.tolist()

    def encode_single(self, text: str) -> List[float]:
        """ç¼–ç å•ä¸ªæ–‡æœ¬"""
        return self.encode([text])[0]

    @property
    def dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.model.get_sentence_embedding_dimension()


# å…¨å±€å•ä¾‹
_embedding_service: Optional[EmbeddingService] = None


def get_embedding_service() -> EmbeddingService:
    """è·å– Embedding æœåŠ¡å•ä¾‹"""
    global _embedding_service
    if _embedding_service is None:
        _embedding_service = EmbeddingService()
    return _embedding_service
```

**Step 4: å®ç°å‘é‡å­˜å‚¨æœåŠ¡**

```python
# backend/src/rag/vectorstore.py
"""
å‘é‡å­˜å‚¨æœåŠ¡
ä½¿ç”¨ ChromaDB ä½œä¸ºå‘é‡æ•°æ®åº“
"""
from typing import Any, Dict, List, Optional

import chromadb
from chromadb.config import Settings as ChromaSettings

from src.core.config import settings

from .embeddings import EmbeddingService, get_embedding_service


class VectorStoreService:
    """
    å‘é‡å­˜å‚¨æœåŠ¡

    å°è£… ChromaDBï¼Œæä¾›æ–‡æ¡£å­˜å‚¨å’Œæ£€ç´¢èƒ½åŠ›
    """

    def __init__(
        self,
        embedding_service: Optional[EmbeddingService] = None,
        persist_directory: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨æœåŠ¡

        Args:
            embedding_service: Embedding æœåŠ¡
            persist_directory: æŒä¹…åŒ–ç›®å½•
        """
        self.embedding_service = embedding_service or get_embedding_service()
        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIR

        self._client: Optional[chromadb.Client] = None
        self._collections: Dict[str, chromadb.Collection] = {}

    @property
    def client(self) -> chromadb.Client:
        """è·å– ChromaDB å®¢æˆ·ç«¯"""
        if self._client is None:
            self._client = chromadb.PersistentClient(
                path=self.persist_directory,
                settings=ChromaSettings(anonymized_telemetry=False),
            )
        return self._client

    def get_collection(self, name: str) -> chromadb.Collection:
        """è·å–æˆ–åˆ›å»ºé›†åˆ"""
        if name not in self._collections:
            self._collections[name] = self.client.get_or_create_collection(
                name=name,
                metadata={"hnsw:space": "cosine"},
            )
        return self._collections[name]

    def add_documents(
        self,
        collection_name: str,
        documents: List[str],
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None,
    ) -> None:
        """
        æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“

        Args:
            collection_name: é›†åˆåç§°
            documents: æ–‡æ¡£åˆ—è¡¨
            metadatas: å…ƒæ•°æ®åˆ—è¡¨
            ids: æ–‡æ¡£ ID åˆ—è¡¨
        """
        collection = self.get_collection(collection_name)

        # ç”Ÿæˆ embeddings
        embeddings = self.embedding_service.encode(documents)

        # ç”Ÿæˆ ID
        if ids is None:
            import uuid
            ids = [str(uuid.uuid4()) for _ in documents]

        collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids,
        )

    def query(
        self,
        collection_name: str,
        query_text: str,
        n_results: int = 5,
        where: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ç›¸ä¼¼æ–‡æ¡£

        Args:
            collection_name: é›†åˆåç§°
            query_text: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°é‡
            where: è¿‡æ»¤æ¡ä»¶

        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        collection = self.get_collection(collection_name)

        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.embedding_service.encode_single(query_text)

        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            where=where,
            include=["documents", "metadatas", "distances"],
        )

        return results

    def delete_collection(self, name: str) -> None:
        """åˆ é™¤é›†åˆ"""
        self.client.delete_collection(name)
        if name in self._collections:
            del self._collections[name]

    def count(self, collection_name: str) -> int:
        """è·å–é›†åˆä¸­çš„æ–‡æ¡£æ•°é‡"""
        collection = self.get_collection(collection_name)
        return collection.count()


# å…¨å±€å•ä¾‹
_vectorstore: Optional[VectorStoreService] = None


def get_vectorstore() -> VectorStoreService:
    """è·å–å‘é‡å­˜å‚¨æœåŠ¡å•ä¾‹"""
    global _vectorstore
    if _vectorstore is None:
        _vectorstore = VectorStoreService()
    return _vectorstore
```

**Step 5: åˆ›å»º __init__.py**

```python
# backend/src/rag/__init__.py
"""
RAG æ¨¡å—
"""
from .embeddings import EmbeddingService, get_embedding_service
from .vectorstore import VectorStoreService, get_vectorstore

__all__ = [
    "EmbeddingService",
    "get_embedding_service",
    "VectorStoreService",
    "get_vectorstore",
]
```

**Step 6: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

```bash
cd backend && python -m pytest tests/unit/test_vectorstore.py -v
```

Expected: PASS

**Step 7: Commit**

```bash
git add backend/src/rag/ backend/tests/unit/test_vectorstore.py
git commit -m "feat: å®ç°å‘é‡å­˜å‚¨æœåŠ¡

- æ·»åŠ  EmbeddingService ä½¿ç”¨ BGE æ¨¡å‹
- æ·»åŠ  VectorStoreService å°è£… ChromaDB
- æ”¯æŒæ–‡æ¡£æ·»åŠ ã€æŸ¥è¯¢ã€åˆ é™¤æ“ä½œ"
```

---

## é˜¶æ®µäºŒæ€»ç»“æ£€æŸ¥ç‚¹

å®Œæˆä»¥ä¸Šä»»åŠ¡åï¼Œä½ åº”è¯¥æœ‰ï¼š

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py          âœ… é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ llm/               âœ… LLM æŠ½è±¡å±‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ health.py          âœ… å¥åº·æ£€æŸ¥ API
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ embeddings.py      âœ… Embedding æœåŠ¡
â”‚   â”‚   â””â”€â”€ vectorstore.py     âœ… å‘é‡å­˜å‚¨æœåŠ¡
â”‚   â””â”€â”€ main.py                âœ… åº”ç”¨å…¥å£
â””â”€â”€ tests/
    â””â”€â”€ unit/                  âœ… å•å…ƒæµ‹è¯•
```

**è¿è¡ŒéªŒè¯ï¼š**

```bash
cd backend
pip install -e ".[dev]"
python -m pytest tests/ -v --cov=src
```

---

## é˜¶æ®µäºŒï¼šAgent èƒ½åŠ›ï¼ˆWeek 3-4ï¼‰

### Task 6: å®ç° Agent åŸºç¡€æ¶æ„

**Files:**
- Create: `backend/src/agents/base.py`
- Create: `backend/src/agents/state.py`
- Create: `backend/src/agents/registry.py`
- Create: `backend/tests/unit/test_agents.py`

**Step 1: å†™å¤±è´¥çš„æµ‹è¯•**

```python
# backend/tests/unit/test_agents.py
import pytest
from src.agents.state import BidEvaluationState


def test_bid_evaluation_state_defaults():
    """æµ‹è¯•è¯„æ ‡çŠ¶æ€é»˜è®¤å€¼"""
    state = BidEvaluationState()

    assert state.tender_id == ""
    assert state.bid_documents == []
    assert state.current_stage == "init"


def test_bid_evaluation_state_with_data():
    """æµ‹è¯•è¯„æ ‡çŠ¶æ€å¸¦æ•°æ®"""
    state = BidEvaluationState(
        tender_id="T001",
        bid_documents=[{"doc_id": "B001"}],
        current_stage="parsing",
    )

    assert state.tender_id == "T001"
    assert len(state.bid_documents) == 1


def test_agent_registry():
    """æµ‹è¯• Agent æ³¨å†Œè¡¨"""
    from src.agents.registry import AgentRegistry

    registry = AgentRegistry()

    # æ³¨å†Œä¸€ä¸ª Agent
    @registry.register("test_agent")
    class TestAgent:
        pass

    assert "test_agent" in registry.list_agents()
    assert registry.get_agent("test_agent") == TestAgent
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

```bash
cd backend && python -m pytest tests/unit/test_agents.py -v
```

**Step 3: å®ç° Agent çŠ¶æ€å®šä¹‰**

```python
# backend/src/agents/state.py
"""
Agent çŠ¶æ€å®šä¹‰
ä½¿ç”¨ TypedDict å®šä¹‰ LangGraph çŠ¶æ€
"""
from typing import Annotated, Any, Dict, List, Optional, TypedDict

from langgraph.graph import add_messages


class BidDocument(TypedDict):
    """æŠ•æ ‡æ–‡æ¡£ç»“æ„"""
    doc_id: str
    company_name: str
    file_path: str
    content: str
    extracted_info: Dict[str, Any]


class ReviewResult(TypedDict):
    """å®¡æŸ¥ç»“æœ"""
    passed: bool
    items: List[Dict[str, Any]]
    warnings: List[str]
    confidence: float


class BidEvaluationState(TypedDict, total=False):
    """
    è¯„æ ‡çŠ¶æ€

    ç”¨äº LangGraph çŠ¶æ€æœºï¼Œè·Ÿè¸ªè¯„æ ‡æµç¨‹ä¸­çš„æ‰€æœ‰æ•°æ®
    """
    # è¾“å…¥
    tender_id: str
    tender_requirements: Dict[str, Any]
    bid_documents: List[BidDocument]

    # æ¶ˆæ¯å†å²ï¼ˆç”¨äº LangGraphï¼‰
    messages: Annotated[list, add_messages]

    # å½“å‰é˜¶æ®µ
    current_stage: str

    # æå–çš„ç»“æ„åŒ–æ•°æ®
    extracted_data: Dict[str, Any]

    # å„ Agent è¾“å‡º
    compliance_result: Optional[ReviewResult]
    technical_result: Optional[ReviewResult]
    commercial_result: Optional[ReviewResult]

    # è¯„åˆ†
    technical_score: Optional[float]
    commercial_score: Optional[float]
    price_score: Optional[float]
    total_score: Optional[float]

    # å¼‚å¸¸æ£€æµ‹
    anomaly_alerts: List[Dict[str, Any]]

    # äººå·¥å®¡æ ¸
    requires_human_review: bool
    human_review_reason: Optional[str]

    # æœ€ç»ˆæŠ¥å‘Š
    final_report: Optional[Dict[str, Any]]

    # é”™è¯¯
    errors: List[str]


def create_initial_state(
    tender_id: str,
    tender_requirements: Dict[str, Any],
    bid_documents: List[BidDocument],
) -> BidEvaluationState:
    """åˆ›å»ºåˆå§‹çŠ¶æ€"""
    return BidEvaluationState(
        tender_id=tender_id,
        tender_requirements=tender_requirements,
        bid_documents=bid_documents,
        messages=[],
        current_stage="init",
        extracted_data={},
        compliance_result=None,
        technical_result=None,
        commercial_result=None,
        technical_score=None,
        commercial_score=None,
        price_score=None,
        total_score=None,
        anomaly_alerts=[],
        requires_human_review=False,
        human_review_reason=None,
        final_report=None,
        errors=[],
    )
```

**Step 4: å®ç° Agent æ³¨å†Œè¡¨**

```python
# backend/src/agents/registry.py
"""
Agent æ³¨å†Œè¡¨
æ”¯æŒåŠ¨æ€æ³¨å†Œå’Œè·å– Agent
"""
from typing import Any, Callable, Dict, Optional, Type


class AgentRegistry:
    """
    Agent æ³¨å†Œè¡¨

    ç”¨äºåŠ¨æ€æ³¨å†Œã€å‘ç°å’Œç®¡ç† Agent
    """

    _instance: Optional["AgentRegistry"] = None

    def __new__(cls) -> "AgentRegistry":
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._agents: Dict[str, Type[Any]] = {}
            cls._instance._factories: Dict[str, Callable] = {}
        return cls._instance

    def register(self, name: str) -> Callable:
        """
        æ³¨å†Œ Agent è£…é¥°å™¨

        Usage:
            @registry.register("my_agent")
            class MyAgent:
                pass
        """
        def decorator(cls: Type[Any]) -> Type[Any]:
            self._agents[name] = cls
            return cls
        return decorator

    def register_factory(self, name: str, factory: Callable) -> None:
        """æ³¨å†Œ Agent å·¥å‚å‡½æ•°"""
        self._factories[name] = factory

    def get_agent(self, name: str) -> Optional[Type[Any]]:
        """è·å–å·²æ³¨å†Œçš„ Agent ç±»"""
        return self._agents.get(name)

    def get_factory(self, name: str) -> Optional[Callable]:
        """è·å– Agent å·¥å‚å‡½æ•°"""
        return self._factories.get(name)

    def list_agents(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ Agent"""
        return list(self._agents.keys())

    def create_agent(self, name: str, *args, **kwargs) -> Any:
        """åˆ›å»º Agent å®ä¾‹"""
        if name in self._factories:
            return self._factories[name](*args, **kwargs)

        agent_cls = self._agents.get(name)
        if agent_cls is None:
            raise ValueError(f"Agent not found: {name}")

        return agent_cls(*args, **kwargs)


# å…¨å±€æ³¨å†Œè¡¨å®ä¾‹
registry = AgentRegistry()


def get_registry() -> AgentRegistry:
    """è·å–å…¨å±€æ³¨å†Œè¡¨"""
    return registry
```

**Step 5: å®ç° Agent åŸºç±»**

```python
# backend/src/agents/base.py
"""
Agent åŸºç±»
"""
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional

from src.services.llm import LLMGateway, get_gateway

from .state import BidEvaluationState


class BaseAgent(ABC):
    """
    Agent æŠ½è±¡åŸºç±»

    æ‰€æœ‰è¯„æ ‡ Agent éƒ½åº”è¯¥ç»§æ‰¿æ­¤ç±»
    """

    def __init__(
        self,
        name: str,
        llm_gateway: Optional[LLMGateway] = None,
        model: Optional[str] = None,
        provider: Optional[str] = None,
    ):
        self.name = name
        self.llm_gateway = llm_gateway or get_gateway()
        self.model = model
        self.provider = provider

    @abstractmethod
    async def run(self, state: BidEvaluationState) -> BidEvaluationState:
        """
        æ‰§è¡Œ Agent é€»è¾‘

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        pass

    async def chat(
        self,
        messages: list,
        temperature: float = 0.7,
        **kwargs,
    ) -> str:
        """è°ƒç”¨ LLM è¿›è¡Œå¯¹è¯"""
        return await self.llm_gateway.chat(
            messages=messages,
            provider=self.provider,
            model=self.model,
            temperature=temperature,
            **kwargs,
        )

    def update_state(
        self,
        state: BidEvaluationState,
        updates: Dict[str, Any],
    ) -> BidEvaluationState:
        """æ›´æ–°çŠ¶æ€"""
        new_state = dict(state)
        new_state.update(updates)
        return BidEvaluationState(**new_state)
```

**Step 6: åˆ›å»º __init__.py**

```python
# backend/src/agents/__init__.py
"""
Agent æ¨¡å—
"""
from .base import BaseAgent
from .registry import AgentRegistry, get_registry, registry
from .state import BidEvaluationState, create_initial_state

__all__ = [
    "BaseAgent",
    "AgentRegistry",
    "get_registry",
    "registry",
    "BidEvaluationState",
    "create_initial_state",
]
```

**Step 7: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

```bash
cd backend && python -m pytest tests/unit/test_agents.py -v
```

**Step 8: Commit**

```bash
git add backend/src/agents/ backend/tests/unit/test_agents.py
git commit -m "feat: å®ç° Agent åŸºç¡€æ¶æ„

- æ·»åŠ  BidEvaluationState çŠ¶æ€å®šä¹‰
- æ·»åŠ  AgentRegistry åŠ¨æ€æ³¨å†Œæœºåˆ¶
- æ·»åŠ  BaseAgent æŠ½è±¡åŸºç±»"
```

---

## é˜¶æ®µä¸€&äºŒ å®Œæˆæ£€æŸ¥

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cd backend && python -m pytest tests/ -v --cov=src

# å¯åŠ¨æœåŠ¡æµ‹è¯•
cd backend && python -m uvicorn src.main:app --reload
```

---

## åç»­é˜¶æ®µé¢„è§ˆ

### é˜¶æ®µä¸‰ï¼šå¤šæ™ºèƒ½ä½“åä½œï¼ˆWeek 5-6ï¼‰

- Task 7: å®ç°åˆè§„å®¡æŸ¥ Agent
- Task 8: å®ç°æŠ€æœ¯è¯„å®¡ Agent
- Task 9: å®ç° LangGraph å·¥ä½œæµç¼–æ’
- Task 10: å®ç° Self-Reflective RAG

### é˜¶æ®µå››ï¼šç”Ÿäº§éƒ¨ç½²ï¼ˆWeek 7-8ï¼‰

- Task 11: å®ç°æ•°æ®åº“æ¨¡å‹
- Task 12: å®ç°ç”¨æˆ·è®¤è¯
- Task 13: æ·»åŠ  RAGAS è¯„ä¼°
- Task 14: Docker éƒ¨ç½²é…ç½®
- Task 15: å‰ç«¯åˆå§‹åŒ–

---

*å®ç°è®¡åˆ’ç‰ˆæœ¬ï¼šv1.0*
*åˆ›å»ºæ—¥æœŸï¼š2026-02-20*
