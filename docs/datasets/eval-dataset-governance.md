# Agent 评估数据集治理规范

> 版本：v2026.02.21-r3  
> 状态：Active  
> 适用范围：离线评估、预发回放、灰度抽样、线上回流

## 1. 目标

1. 保证评估结果可复现、可比较、可持续演进。
2. 让数据集版本成为发布门禁的一部分。
3. 建立线上失败样本到离线改进的闭环。

## 2. 数据集分层

### D1 黄金集（稳定基准）

1. 覆盖核心业务场景。
2. 每次发布必须跑全量。

### D2 反例集（对抗样本）

1. 幻觉诱导。
2. 引用缺失。
3. 冲突信息。
4. 越权诱导。

### D3 漂移集（环境变化）

1. 新模板文档。
2. 扫描噪声。
3. 版式变化。
4. 跨语种样本。

### D4 回流集（线上样本）

1. DLQ 典型失败样本。
2. 人审改判样本。
3. 线上投诉样本。

## 3. 样本结构（最小）

每个样本必须包含：

1. `sample_id`
2. `dataset_version`
3. `tenant_scope`
4. `task_type`
5. `input_payload_ref`
6. `expected_output_or_constraints`
7. `expected_citations`
8. `risk_label`
9. `source`（golden/adversarial/drift/online_feedback）
10. `created_at`

## 4. 版本规则

### 4.1 命名

`<dataset_name>-v<major>.<minor>.<patch>`

### 4.2 语义

1. `major`：标签语义或评估口径变更。
2. `minor`：新增样本或新增场景。
3. `patch`：标注修复与元数据修正。

## 5. 标注与质控

1. 核心样本双人标注复核。
2. 不一致样本进入仲裁流程。
3. 每次发布前抽检不少于 10%。
4. 高风险样本必须有人审解释记录。

## 6. 自动样本生成（P1）

1. 允许使用 DeepEval Synthesizer 生成候选样本。
2. 自动样本必须通过人工抽检后才能入库。
3. 自动样本需标记 `generated=true` 与生成策略。

## 7. 执行流程

```text
数据准备 -> 版本冻结 -> 评估执行 -> 指标对比 -> 结果归档 -> 失败样本回流
```

## 8. 退役与保留

1. 连续两个版本无代表性的样本可退役。
2. 退役样本保留索引与原因记录。
3. 涉及事故复盘的样本不得删除。

## 9. 与发布门禁关系

1. 没有冻结数据集版本，不允许发布。
2. 数据集版本必须写入发布记录。
3. 发布后发现问题必须补回归样本。

## 10. 验收标准

1. 数据集版本可追溯。
2. 标注质量可抽检验证。
3. 线上失败样本能稳定回流。

## 11. 参考来源（核验：2026-02-21）

1. RAGAS: https://github.com/explodinggradients/ragas
2. DeepEval: https://github.com/confident-ai/deepeval
