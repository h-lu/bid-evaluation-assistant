# ============================================================
# 评标助手系统环境配置模板
# 复制此文件为 .env 并根据需要修改
# cp .env.example .env
# ============================================================

# ============================================================
# LLM API 配置（OpenAI 兼容）
# ============================================================
# 方案 1: OpenRouter（推荐，支持多种模型）
OPENAI_API_KEY=sk-or-v1-your-openrouter-key
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# 方案 2: OpenAI 官方
# OPENAI_API_KEY=sk-your-openai-key
# OPENAI_BASE_URL=https://api.openai.com/v1

# 方案 3: 其他兼容 API（如 SiliconFlow、DeepSeek）
# OPENAI_API_KEY=sk-your-key
# OPENAI_BASE_URL=https://api.siliconflow.cn/v1

# ============================================================
# LLM 模型配置（评分 / 解释生成）
# ============================================================
LLM_PROVIDER=openai
LLM_MODEL=openai/gpt-5-mini
LLM_FALLBACK_MODEL=openai/gpt-5-mini
LLM_TEMPERATURE=0.1

# 替代模型选项：
# LLM_MODEL=openai/gpt-4o-mini        # 更快更便宜
# LLM_MODEL=anthropic/claude-3.5-haiku # Claude 系列
# LLM_MODEL=google/gemini-flash-1.5   # Gemini 系列

# ============================================================
# Embedding 模型配置（向量检索）
# ============================================================

# 方案 1: OpenAI API（推荐：通过 OpenRouter 或官方 API）
EMBEDDING_BACKEND=openai
EMBEDDING_MODEL=openai/text-embedding-3-small

# 方案 2: 本地 Sentence Transformers（离线/无 API Key）
# EMBEDDING_BACKEND=sentence-transformers
# EMBEDDING_MODEL=all-MiniLM-L6-v2

# 方案 3: Ollama 本地嵌入
# EMBEDDING_BACKEND=ollama
# EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_BASE_URL=http://localhost:11434/v1

# 方案 4: Simple（仅测试用，SHA256 哈希 - 非真实向量）
# EMBEDDING_BACKEND=simple
# EMBEDDING_DIM=128

# ============================================================
# Rerank 重排序配置
# ============================================================

# 方案 1: Jina API（推荐：中文优化好，免费额度大）
RERANK_BACKEND=jina
JINA_API_KEY=jina-your-jina-key
RERANK_TIMEOUT_MS=5000

# 方案 2: 本地 Cross-Encoder（离线，需下载模型 ~88MB）
# RERANK_BACKEND=cross-encoder
# RERANK_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2
# RERANK_TIMEOUT_MS=5000

# 方案 3: 简单 TF-IDF（最快，质量一般）
# RERANK_BACKEND=simple

# 方案 4: Cohere API（云端，质量高）
# RERANK_BACKEND=cohere
# COHERE_API_KEY=your-cohere-key
# RERANK_TIMEOUT_MS=5000

# ============================================================
# 评估与测试配置
# ============================================================
# RAGAS / DeepEval 评估模型
RAGAS_MODEL=openai/gpt-5-mini
DEEPEVAL_MODEL=openai/gpt-5-mini
RAGAS_DO_NOT_TRACK=true

# Mock LLM（测试用，返回确定性结果，不调用真实 API）
# MOCK_LLM_ENABLED=true
MOCK_LLM_ENABLED=false

# ============================================================
# Ollama 本地模型配置
# ============================================================
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen2.5:7b

# ============================================================
# 成本与安全控制
# ============================================================
TASK_TOKEN_BUDGET=50000

# JWT 安全配置（生产环境必须修改）
# JWT_SHARED_SECRET=your-32-byte-secret-key-min-length
# JWT_ISSUER=bid-evaluation-assistant
# JWT_AUDIENCE=api

# ============================================================
# 存储与队列配置
# ============================================================
# PostgreSQL（生产环境）
# POSTGRES_DSN=postgresql://user:pass@localhost:5432/bea

# Redis（生产环境队列）
# REDIS_URL=redis://localhost:6379/0

# Chroma 持久化目录
# CHROMA_PERSIST_DIR=./data/chroma

# 对象存储
# BEA_OBJECT_STORAGE_BACKEND=s3
# AWS_ACCESS_KEY_ID=your-key
# AWS_SECRET_ACCESS_KEY=your-secret
# S3_BUCKET=your-bucket

# ============================================================
# 工作流与运行时配置
# ============================================================
# WORKFLOW_CHECKPOINT_BACKEND=postgres  # or memory
# WORKER_MAX_RETRIES=3
# WORKER_RETRY_BACKOFF_BASE_MS=1000

# ============================================================
# 监控与告警
# ============================================================
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OBS_METRICS_NAMESPACE=bea
# OBS_ALERT_WEBHOOK=https://hooks.slack.com/services/...

# ============================================================
# 发布与灰度配置
# ============================================================
# RELEASE_CANARY_RATIO=0.1
# RELEASE_CANARY_DURATION_MIN=30
# P6_READINESS_REQUIRED=true
